---
title: "Group Project"
output: html_document
date: "2025-11-19"
---

## Setup Data

Load data

```{r}
library(dplyr)
library(ggplot2)

data = read.csv("song_data.csv")
head(data)
```

Drop the `song_name` column as this is just for identifying the song.
```{r}
to_drop = c("song_name")
data = data[, !(names(data) %in% to_drop)]
```

Get the column names
```{r}
column_names = colnames(data)
print(column_names)
```

From the description of the data, we know that `key`, `audio_mode` and `time_signature` are categorial data. So we can split the column names into categorial and continuous data
```{r}
categorial_col_names = c("key", "audio_mode", "time_signature")
continuous_col_names = column_names[!column_names %in% categorial_col_names]

cat("Categorial: ", categorial_col_names, "\n")
cat("Continuous: ", continuous_col_names, "\n")
```

## Data Cleaning

Check if there are duplicate songs in our dataset
```{r}
length(unique(data)) == nrow(data)
```

Since the number of unique songs is not the same as the number of rows in data, we can see that there are duplicate data in our dataset.

Drop the exact duplicate data.
```{r}
data = unique(data)
```

Check for missing data.
```{r}
which(is.na(data))
```

Set categorial and continuous data
```{r}
continuous_data = data[, (names(data) %in% continuous_col_names)]
categorial_data = data[, (names(data) %in% categorial_col_names)]
```

Since integer(0) is being returned, this means that there is no missing data to clean.

Check values and frequency of the categorial data
```{r}
for (name in categorial_col_names) {
  frequency_table = table(data[[name]])
  print(name)
  print(frequency_table)
  print(prop.table(frequency_table))
  cat("\n")
}
```

We can see that there is no inconsistent data for the categorial data.

Apply factors to the categorial data
```{r}
for (name in categorial_col_names) {
  data[[name]] = factor(data[[name]])
}
```

## Data Exploration

Display the mean, median, and standard deviation of each of the continuous data
```{r}
for (name in continuous_col_names) {
  curr_col = data[[name]]
  
  curr_col_mean = mean(curr_col)
  curr_col_median = median(curr_col)
  curr_col_sd = sd(curr_col)

  cat(name, "\n")
  cat("Mean: ", curr_col_mean, "\n")
  cat("Median: ", curr_col_median, "\n")
  cat("Standard Deviation", curr_col_sd, "\n");
  cat("\n")
}
```

Plot a density of each continuous column
```{r}
options(repr.plot.width = 2, repr.plot.height = 2)

for (name in continuous_col_names) {
  print(
    ggplot(data, aes(x = data[[name]])) +
      geom_histogram(aes(y = ..density..), bins = 30, fill = "skyblue", color = "black") +
      geom_density(linewidth = 1, color = "red") +
      labs(title = paste("Histogram of", name)) +
      theme_minimal(base_size = 10) # smaller text for compact plot
  )
}
```

Plot a bar graph for each categorial data
```{r}
for (name in categorial_col_names) {
  print(ggplot(data, aes(x=data[[name]])) + geom_bar() + labs(title=paste("Count of", name)))
}
```


Plot a scatter plot comparing the song popularity with predictors
```{r}
for (name in continuous_col_names) {
  if (name == "song_popularity") {
    next
  }
  
  print(ggplot(data, aes(x=data[[name]], y=song_popularity)) + geom_point(size = 2, scale=23) + labs(title=paste("Scatterplot of song popularity vs", name)))
}
```

Display variance-covariance matrix
```{r}
varcov_matrix = cov(continuous_data)
print(varcov_matrix)
```

Display correlation matrix
```{r}
cor_matrix = cor(continuous_data)
print(cor_matrix)
```

Using the correlation matrix, check for high correlation
```{r}
library(corrplot)
corrplot(cor_matrix)
```
```{r}
# Diagnostics for multicollinearity
# Correlation heat map shows high correlations between predictor variables
library(reshape2)
melted_song <- melt(cor_matrix)
ggplot(data = melted_song, aes(Var1, Var2, fill = value)) + 
  geom_tile() + 
  geom_text(aes(label = ifelse(abs(value) > 0.3, round(value, 2), "")), 
            size = 2.8, color = "white") +  # Only show values > |0.3|
  scale_fill_viridis_c(option = "plasma", name = "Correlation") +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1, size = 8),
    axis.text.y = element_text(size = 8)
  )
```

We can see high correlation between some predictors:
- loudness and energy
- energy and acousticness
- loudness and acousticness

Split into training and testing data
```{r}
set.seed(123456789)
data_size = nrow(data)
training_data_size = floor(data_size * 0.8)
training_index = sample(seq_len(data_size), size=training_data_size)

training_data = data[training_index,]
testing_data = data[-training_index,]
```

Standardized and center data
```{r}
continuous_predictors = continuous_col_names[continuous_col_names != "song_popularity"]

training_mean = sapply(training_data[continuous_predictors], mean)
training_sd = sapply(training_data[continuous_predictors], sd)

training_data[continuous_predictors] = scale(training_data[continuous_predictors], center=training_mean, scale=training_sd)
testing_data[continuous_predictors] = scale(testing_data[continuous_predictors], center=training_mean, scale=training_sd)
```

## Model Selection

### Main Effect Model

Setup
```{r}
model_statistics <- function(model, model_training_data) {
  # MSE of the model
  sigma2 = summary(model)$sigma^2
  
  # RSS of the model
  RSS = sum(residuals(model)^2)
  
  # number of parameters including intercept
  p = length(coef(model))
  
  # sample size
  n = nrow(model_training_data)
  
  # Mallows' Cp
  Cp = RSS / sigma2 - (n - 2*p)
  
  # residuals
  e = residuals(model)
  
  # leverage values
  h = hatvalues(model)
  
  # PRESS
  PRESS = sum((e / (1 - h))^2)
  
  cat("Cp:", Cp, "\n")
  cat("AIC:", AIC(model), "\n")
  cat("BIC:", BIC(model), "\n")
  cat("PRESS:", PRESS, "\n")
}

model_prediction <- function(model, model_testing_data) {
  predictions <- predict(model, newdata = model_testing_data)
  MSPE <- mean((model_testing_data$song_popularity - predictions)^2)
  
  cat("MSPE:", MSPE, "\n")
}
```

Fit the main effect model
```{r}
full_main_model = lm(song_popularity ~ song_duration_ms + acousticness + danceability + energy + instrumentalness + liveness + loudness + speechiness + tempo + audio_valence + key + audio_mode + time_signature, data=training_data)

summary(full_main_model)
```

Check for outliers
```{r}
studentized_residual = rstudent(full_main_model)

n = dim(training_data)[1]
p.prime = length(coef(full_main_model))

t.crit = qt(1-0.05/(2*n), n - p.prime - 1)

which(abs(studentized_residual) > t.crit) 
# number of outliers based on studentized residual
```

There are no outliers

Check for influential points
```{r}
DFFITS  <- dffits(full_main_model)
DFFITS_influential <- which(abs(DFFITS) > 1)
cat("DFFITS:", DFFITS_influential, "\n")

D <- cooks.distance(full_main_model)
D_influential <- which(D > (4 / n))
# cat("Cook's Distance:", D_influential, "\n")

DFBETAS <- dfbetas(full_main_model)
DFBETAS_influential_rows <- which(
  apply(abs(DFBETAS) > (2 / sqrt(n)), 1, any)
)
# cat("DFBETAS:", DFBETAS_influential_rows, "\n")

print(length(DFFITS_influential))
print(length(D_influential))
print(length(DFBETAS_influential_rows))

```

Plot influential points
```{r}
library(ggpubr)
library(olsrr)

ols_plot_dffits(full_main_model)
ols_plot_cooksd_chart(full_main_model)
ols_plot_dfbetas(full_main_model)
```

Get the data of the influential points
```{r}
influential_idx = sort(unique(c(DFFITS_influential, D_influential, DFBETAS_influential_rows)))
influential_data = training_data[influential_idx, ]
```

Get dataset with influential points dropped
```{r}
dropped_training_data = training_data[-influential_idx,]
```

#### Main Effect Model on data with influential points

```{r}
summary(full_main_model)
```

Check LINE Assumptions
```{r}
plot(full_main_model)
```

We can see that normality assumption is violated. We can check this with Shapiro-Wilk's test
```{r}
set.seed(123456789)

residual = full_main_model$residuals
residual_sample = sample(residual, 5000)

shapiro.test(residual_sample)
```

Since the p-value < 0.5, we can see that normality assumption is violated.

We can apply box-cox transformation to try to fix this. We know that all values for response variable needs to be positive to apply box-cox.
Check minimum value of song_popularity
```{r}
min(training_data$song_popularity)
```

Since the minimum is not positive, we can apply a shift by 1 to make song_popularity positive.
```{r}
training_data$song_popularity_shifted = training_data$song_popularity + 1
```

Refit model to use song_popularity_shifted
```{r}
full_main_model_shifted = lm(song_popularity_shifted ~ song_duration_ms + acousticness + danceability + energy + instrumentalness + liveness + loudness + speechiness + tempo + audio_valence + key + audio_mode + time_signature, data=training_data)
```

We can find best lambda value for box-cox transformation.
```{r}
library(MASS)
boxcox_full_main = boxcox(full_main_model_shifted)
```

Get the best lambda value
```{r}
lambda_full_main = boxcox_full_main$x[which.max(boxcox_full_main$y)]
lambda_full_main
```

Apply box-cox transformation
```{r}
training_data$song_popularity_box_cox = (training_data$song_popularity_shifted^lambda_full_main - 1) / lambda_full_main
```

Fit new model with box-cox transformation applied
```{r}
full_main_model_box_cox = lm(song_popularity_box_cox ~ song_duration_ms + acousticness + danceability + energy + instrumentalness + liveness + loudness + speechiness + tempo + audio_valence + key + audio_mode + time_signature, data=training_data)

summary(full_main_model_box_cox)
```

Check LINE assumptions after applying box-cox
```{r}
plot(full_main_model_box_cox)
```

We can see that the normality assumption got slightly better but still is violated.

Check Shapiro Wilk's test again
```{r}
set.seed(123456789)

residual_box_cox = full_main_model_box_cox$residuals
residual_box_cox_sample = sample(residual_box_cox, 5000)

shapiro.test(residual_sample)
```

The p-value from the Shapiro-Wilk test is still less than 0.5, so normality is still violated.

Since box-cox transformation did not improve the residual diagonsitics, we will continue using the original response variable without box-cox transformation.

We can also check for multicollinearity. We will need to check VIF.
```{r}
library(car)
vif(full_main_model)
```

We can see that none of the VIF values > 5, therefore there is no multicollinearity evident.

#### Approach 1: Using Main Effect Model

This is the model with all predictors
```{r}
summary(full_main_model)
```

Print model statistics
```{r}
model_statistics(full_main_model, training_data)
```

#### Approach 2: Dropping predictors using F-test

Now, we can check which predictors we should drop. First, we can find predictors where their p-values > 0.5
```{r}
which(summary(full_main_model)$coefficients[, "Pr(>|t|)"] >= 0.05)
```

We can see that song_duration_ms, speechiness, key and time_signature all have p-values greater than 0.5. We can do an F-test to see if we can drop these predictors.

Fit a reduced model
```{r}
reduced_model = lm(song_popularity ~ acousticness + danceability + energy + instrumentalness + liveness + loudness + tempo + audio_valence + audio_mode, data=training_data)
```

Display ANOVA table
```{r}
anova(reduced_model, full_main_model)
```

Do an F-test to see if we can drop song_duration_ms, speechiness, key and time_signature
```{r}
f_stat = ((4806541 - 4797783) / 17) / (4797783 / 11912)
f_crit_val = qf(0.95, df1=17, df2=11912)

f_stat < f_crit_val
```

Since f_stat < f_crit_val, we fail to reject the hypothesis. Therefore, we can drop song_duration_ms, speechiness, key and time_signature.

Therefore, this is our final model using F-test
```{r}
summary(reduced_model)
```

Print model statistics
```{r}
model_statistics(reduced_model, training_data)
```

#### Approach 3: Apply Stepwise AIC without boxcox transformation

```{r}
simple_model = lm(song_popularity ~ 1, data=training_data)
stepwise_model = stepAIC(simple_model, scope = list(upper=full_main_model, lower=simple_model),direction="both",trace=TRUE)
```

This is the final model
```{r}
summary(stepwise_model)
```

Print model statistics
```{r}
model_statistics(stepwise_model, training_data)
```

### Interaction Model on data with influential points

Fit a full interaction model without box cox transformation
```{r}
full_interaction_model = lm(data = training_data, song_popularity~ song_duration_ms +acousticness+
                  danceability+ energy+ instrumentalness+ liveness+ loudness+ speechiness+
                  tempo+ audio_valence + as.factor(key)+ as.factor(audio_mode)+ as.factor(time_signature)+
                  acousticness:loudness+ audio_valence:danceability+ audio_valence:energy+ energy:loudness+
                  acousticness:energy+ energy:instrumentalness+ loudness:instrumentalness+
                  danceability:speechiness+ audio_valence:loudness+ as.factor(key):song_duration_ms
                  +as.factor(key):acousticness+ as.factor(key):danceability+ as.factor(key):energy+
                  as.factor(key):instrumentalness+ as.factor(key):liveness+ as.factor(key):loudness+ 
                  as.factor(key):speechiness+ as.factor(key):tempo+ as.factor(key):audio_valence+
                  song_duration_ms:as.factor(audio_mode) +acousticness:as.factor(audio_mode)+
                  danceability:as.factor(audio_mode)+ energy:as.factor(audio_mode)+ 
                  instrumentalness:as.factor(audio_mode)+ liveness:as.factor(audio_mode)+ 
                  loudness:as.factor(audio_mode)+ speechiness:as.factor(audio_mode)+
                  tempo:as.factor(audio_mode)+ audio_valence:as.factor(audio_mode)+
                  song_duration_ms:as.factor(time_signature) +acousticness:as.factor(time_signature)+
                  danceability:as.factor(time_signature)+ energy:as.factor(time_signature)+
                  instrumentalness:as.factor(time_signature)+ liveness:as.factor(time_signature)+
                  loudness:as.factor(time_signature)+ speechiness:as.factor(time_signature)+
                  tempo:as.factor(time_signature)+ audio_valence:as.factor(time_signature))
```

#### Approach 0: Full interaction model without box-cox transformation

This is the full interaction model
```{r}
summary(full_interaction_model)
```

Print model statistics
```{r}
model_statistics(full_interaction_model, training_data)
```

#### Approach 2: Drop predictors using F-test

Now, we can check which predictors we should drop. First, we can find predictors where their p-values > 0.5
```{r}
which(summary(full_interaction_model)$coefficients[, "Pr(>|t|)"] >= 0.05)
```

```{r}
reduced_interaction_model = lm(song_popularity ~ instrumentalness + audio_valence + as.factor(key) + as.factor(audio_mode) + as.factor(time_signature), data=training_data)
```

```{r}
anova(reduced_interaction_model, full_interaction_model)
```

```{r}
f_stat = ((4845417 - 4639748) / 169) / (4639748 / 11751)
f_crit_val = qf(0.95, df1=169, df2=11751)

f_stat < f_crit_val
```

We cannot drop these predictors.

#### Approach 3: Drop predictors stepwise AIC

Apply stepwise AIC to the full interaction model
```{r}
simple_model_interaction = lm(song_popularity ~ 1, data=training_data)
stepwise_interaction_model = stepAIC(simple_model_interaction, scope = list(upper=full_interaction_model, lower=simple_model_interaction),direction="both",trace=TRUE)
```

This is the final interaction model after stepwise AIC
```{r}
summary(stepwise_interaction_model)
```

Print model statistics
```{r}
model_statistics(stepwise_interaction_model, training_data)
```

### Ridge and LASSO Regression Models

Include ridge and lasso regression

### Main Effect Model without influential points

Drop influential points and fit
```{r}
full_main_model_dropped = lm(song_popularity ~ song_duration_ms + acousticness + danceability + energy + instrumentalness + liveness + loudness + speechiness + tempo + audio_valence + key + audio_mode + time_signature, data=dropped_training_data)

summary(full_main_model_dropped)
```

Check LINE assumptions
```{r}
plot(full_main_model_dropped)
```

We can see that normality assumption is violated. We can check this with Shapiro-Wilk's test
```{r}
set.seed(123456789)

residual_dropped = full_main_model_dropped$residuals
residual_dropped_sample = sample(residual_dropped, 5000)

shapiro.test(residual_dropped_sample)
```

Since p-value < 0.5, we can see that normality assumption is violated.

We can apply box-cox transformation to try to fix this. We know that all values for response variable needs to be positive to apply box-cox.
Check minimum value of song_popularity
```{r}
min(dropped_training_data$song_popularity)
```

Since response variable is all positive, we can apply box cox transformation.

We can find best lambda value for box-cox transformation.
```{r}
library(MASS)
boxcox_full_main_dropped = boxcox(full_main_model_dropped)
```

Get the best lambda value
```{r}
lambda_full_main_dropped = boxcox_full_main_dropped$x[which.max(boxcox_full_main_dropped$y)]
lambda_full_main_dropped
```

Apply box-cox transformation
```{r}
dropped_training_data$song_popularity_box_cox = (dropped_training_data$song_popularity^lambda_full_main_dropped - 1) / lambda_full_main_dropped
```

Fit model with box-cox
```{r}
full_main_model_dropped_box_cox = lm(song_popularity_box_cox ~ song_duration_ms + acousticness + danceability + energy + instrumentalness + liveness + loudness + speechiness + tempo + audio_valence + key + audio_mode + time_signature, data=dropped_training_data)

summary(full_main_model_dropped_box_cox)
```

Check LINE assumptions after applying box-cox
```{r}
plot(full_main_model_dropped_box_cox)
```

We can see that the normality assumption got slightly better but still is violated.

Check Shapiro Wilk's test again
```{r}
set.seed(123456789)

residual_dropped_box_cox = full_main_model_dropped_box_cox$residuals
residual_dropped_box_cox_sample = sample(residual_dropped_box_cox, 5000)

shapiro.test(residual_dropped_box_cox_sample)
```

The p-value from the Shapiro-Wilk test is still less than 0.5, so normality is still violated.

Since box-cox transformation did not improve the residual diagonsitics, we will continue using the original response variable without box-cox transformation.

We can also check for multicollinearity. We will need to check VIF.
```{r}
library(car)
vif(full_main_model_dropped)
```

We can see that none of the VIF values > 5, therefore there is no multicollinearity evident.

Therefore the final model is:
```{r}
summary(full_main_model_dropped)
```

Print model statistics
```{r}
model_statistics(full_main_model_dropped, dropped_training_data)
```

### Interaction Model without influential points

Fit the interaction model 
```{r}
interaction_model_dropped = lm(song_popularity ~ instrumentalness + audio_valence + 
    danceability + liveness + loudness + energy + acousticness + 
    as.factor(audio_mode) + speechiness + instrumentalness:loudness + 
    audio_valence:energy + loudness:acousticness + loudness:energy + 
    as.factor(audio_mode):speechiness, data = dropped_training_data)
summary(interaction_model_dropped)
```

Print model statistics
```{r}
model_statistics(interaction_model_dropped, dropped_training_data)
```

### Model Validation

For the data with influential points, we found that the stepwise interaction model was the best model.
For the data without influential points, we found that the interaction model was the best model.

Interaction Model with influential points
```{r}
model_prediction(stepwise_interaction_model, testing_data)
```

Interaction Model without influential points
```{r}
model_prediction(interaction_model_dropped, testing_data)
```

Since the MSPE is not significantly different between having and not having dropped influential points, we can see that the best model is the interaction model without the influential points.

### Best Model

Therefore the best model is:
```{r}
summary(interaction_model_dropped)
```

Print model statistics
```{r}
model_statistics(interaction_model_dropped, dropped_training_data)
```


